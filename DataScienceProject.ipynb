{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akjieettt/data-science-final-project/blob/main/DataScienceProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F1 Pit Stop Strategy Analysis: How Pit Stops Affect Race Outcomes\n",
        "\n",
        "**Group Members**: Hrishi Kabra and Kiet Huynh\n",
        "\n",
        "**Project Website**: https://akjieettt.github.io/data-science-final-project/\n",
        "\n",
        "# **Collaboration Plan**\n",
        "\n",
        "**Team Coordination:**\n",
        "- Set up a private GitHub repository to coordinate all code, share datasets, and track progress\n",
        "- Each member works on separate branches to implement features, which are merged via pull requests after code review to ensure consistency\n",
        "\n",
        "**Technologies Used:**\n",
        "- Version Control: Git and GitHub for source code management and collaboration\n",
        "- Development Environment: Visual Studio Code Live Share, Google Colab, and Jupyter Notebooks for data analysis and prototyping\n",
        "- Communication Tools: Small Family Collaboration Hub for offline discussions, FaceTime for online discussions and Google Docs for shared notes\n",
        "\n",
        "**Meeting Schedule:**\n",
        "- Consistently meet offline 2 - 3 times per week for 1 - 3 hours per session to discuss progress, solve problems, and coordinate tasks\n",
        "- Outside of scheduled meetings, we communicate asynchronously via iMessage to stay aligned and share updates\n",
        "\n",
        "**Task Management:**\n",
        "- Tasks are divided based on expertise and interest\n",
        "- Progress is tracked via a shared progress table (in a spreadsheet) to ensure deadlines are met and responsibilities are clear"
      ],
      "metadata": {
        "id": "8tJvGC8jjVr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Milestone 1\n",
        "For Milestone 1 you should generate a roughly 1 page writeup (~500 words) listing a partner and one to three datasets that you are considering working with and why. For each dataset you should generate at least one question you hope to answer with that data as well as a small amount of ETL including 3-5 interesting stats and one graph. This is just an outline to make sure you are thinking and is not a commitment in any way. This will be published on your GitHub IO page so this also makes sure you’ve figured out how to get it uploaded!\n",
        "\n",
        "You must also include a short collaboration plan describing how you are working together, what technologies you are using, and when / how often you are meeting to work on this project. Examples include: we setup a private Github repo to coordinate code and we met on Zoom X times…. or even we used LiveShare for CS Code Teletype for Atom or RemoteCollab for Sublime. Failure to turn in a collaboration plan that shows you coordinated will be a loss of professionalism points. The turned in result will need to reflect the understanding of both students\n",
        "\n",
        "You should load one of these datasets and parse it into shape using the principles of tidy data discussed in class and display the data table in a reasonable format so demonstrating what data you have. This is to show that you have figured out how to get the data into your system and does not need to be a final version, but it should show that you can read in a data source for your project. You should clearly discuss the data and what challenges you had in formatting it.\n",
        "\n",
        "You should submit the notebook through Canvas. In the absolute first cell of your notebook you must include your names, project title, and a hyperlink to your webpage at github.io; the webpage must be publicly readable on the internet (i.e, live) and must contain the same work that is in the submitted notebook. That is: the first cell of your notebook must be a markdown cell with a hyperlink to the generated webpage up at yourname.github.io. If this is not correct you will lose points. After this first cell you should continue with the other requirements including a description of your project, links to the data and other relevant resources, a collaboration plan, and the project goals.\n",
        "\n",
        "\n",
        "(4 Points) Professionalism: You have used both code comments and markdown cells to professionally and clearly document your work including having a clear and clean notebook; linking to resources and documents; and doing so with code that is reasonable and efficient. Your notebook is correct and contains the required links. In addition, you have written code that is interpretable – it contains comments where needed to understand, variable names are reasonable, and code that is reasonable and efficient. You have followed directions to turn in the file, clearly labeling everything. You have cited all sources and how you used them in the written portion of your answers.\n",
        "(4 Points) Website: Website is up, link was submitted and is correct. Notebook is professional and clean, the names of the group members, a title for the project, and other good practices as this is publicly posted.\n",
        "(4 Points) Project Plan: Project plan is in place, relevant data is identified and links are provided, there are draft questions or hypothesis that the student is going to explore. Plan clearly explains how the data could be used to answer the question and addresses whether or not other data is needed.\n",
        "(4 Points) Extraction, Transform, and Load (ETL): At least one data set(s) are loaded correctly using web scraping other techniques. The data is discussed in terms of what it is and how it could be used to answer the question of study. Where the data comes from and how it is collected is clearly documented with links and other relevant details. The data is imported and tidy according to the principles discussed in class. Dtypes are set properly and displayed within the notebook, NaN’s and other techniques are used following best practices discussed in class.\n",
        "(4 Points) Exploratory Data Analysis (EDA): You should do some light EDA on your data and show 3 - 5 interesting summary statistics or groups that relate to the questions you are asking of your data along with a brief justification as to why these statistics are interesting and relevant. You should also give at least 1 graphic which shows some interesting property or distribution of your data (skew, histogram, scatter plot) etc., and explain why this is relevant to your question.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3h9e2YMEqfzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loading all F1 datasets\n",
        "df_circuits = pd.read_csv(\"/content/circuits.csv\")\n",
        "df_status = pd.read_csv(\"/content/status.csv\")\n",
        "df_lap_times = pd.read_csv(\"/content/lap_times.csv\")\n",
        "df_sprint_results = pd.read_csv(\"/content/sprint_results.csv\")\n",
        "df_drivers = pd.read_csv(\"/content/drivers.csv\")\n",
        "df_races = pd.read_csv(\"/content/races.csv\")\n",
        "df_constructors = pd.read_csv(\"/content/constructors.csv\")\n",
        "df_constructor_standings = pd.read_csv(\"/content/constructor_standings.csv\")\n",
        "df_qualifying = pd.read_csv(\"/content/qualifying.csv\")\n",
        "df_driver_standings = pd.read_csv(\"/content/driver_standings.csv\")\n",
        "df_constructor_results = pd.read_csv(\"/content/constructor_results.csv\")\n",
        "df_pit_stops = pd.read_csv(\"/content/pit_stops.csv\")\n",
        "df_seasons = pd.read_csv(\"/content/seasons.csv\")\n",
        "df_results = pd.read_csv(\"/content/results.csv\")\n",
        "\n",
        "print(f\"Loaded all 14 datasets\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezC_WfHmjfSA",
        "outputId": "cb3668df-e05f-4906-d0f0-a03ff8ef2d20"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded all 14 datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss4o4OpqtiuK",
        "outputId": "773d3a07-c7cc-4fb8-b74a-531a71067083"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/drive/MyDrive/DataScienceProject.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUi6S7oOr69e",
        "outputId": "6005370d-2c45-4dfc-ad72-afd5a925044d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/DataScienceProject.ipynb to html\n",
            "[NbConvertApp] Writing 284454 bytes to /content/drive/MyDrive/DataScienceProject.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}